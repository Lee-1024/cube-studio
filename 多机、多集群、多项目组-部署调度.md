# 配置文件所在地

本地调试时：(启动方式:install/docker/目录下执行`docker-compose up`)

 - k8s集群的config文件：在install/docker/kubeconfig/下面  
 - 配置文件config.py文件：在install/docker/config.py中
 - 启动文件entrypoint.sh文件：在install/docker/entrypoint.sh中

线上部署时：(启动方式：install/kubernetes/目录下执行 `kubectl apply -k cube/overlays`）

 - k8s集群的config文件：在install/kubernetes/kubeconfig/下面  
 - 配置文件config.py文件：在install/kubernetes/cube/overlays/config/config.py中
 - 启动文件entrypoint.sh文件：在install/kubernetes/cube/overlays/config/entrypoint.sh中

# 机器标签管理

机器通过label进行管理，所有的调度机器由平台控制，不由用户直接控制。

开发训练服务机器管理：
- 对于cpu的train/notebook/service会选择cpu=true的机器  
- 对于gpu的train/notebook/service会选择gpu=true的机器  

- 训练任务会选择train=true的机器  
- notebook会选择notebook=true的机器  
- 服务化会选择service=true的机器  
- 不同项目的任务会选择对应org=xx的机器。默认为org=public 
- 可以通过gpu-type=xx表示gpu的型号，比如gpu-type=V100或gpu-type=T4，在配置gpu算力时也可以同步配置gpu型号。例如2(T4)表示2张T4卡。

控制器机器管理：
- mysql=true 部署mysql服务的机器
- redis=true 部署mysql服务的机器
- kubeflow-dashobard=true 部署cube服务的机器
- kubeflow=true 部署kubeflow的机器
- isito=true 部署istio的机器
- knative=true 部署knative的机器
- monitoring=true 部署prometheus的机器


# 单集群多机

### 1、[单机完成控制组件部署](https://github.com/tencentmusic/cube-studio/wiki/1.2-%E3%80%81%E5%B9%B3%E5%8F%B0%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2)

### 2、集群扩容

在新机器上只需要准备好镜像pull_image_kubeflow.sh和pull_image_rancher.sh，不需要再执行start.sh脚本

在rancher界面，将新机器加入rancher集群，新机器只需要为worker，并且为机器添加label。

### 3、分布式存储

目前机器学习平台依赖强io性能的分布式存储。  建议使用ssd的ceph作为分布式存储。并注意配置好开机自动挂载避免在机器重启后挂载失效

 ！！！重要：分布式文件系统需要挂载到每台机器的/data/k8s/下面，当然也可以挂载其他目录下，以软链的形式链接到/data/k8s/下 

需要每台机器都有对应的目录/data/k8s为分布式存储目录
```bash  
mkdir -p /data/k8s/kubeflow/minio  
mkdir -p /data/k8s/kubeflow/global  
mkdir -p /data/k8s/kubeflow/pipeline/workspace  
mkdir -p /data/k8s/kubeflow/pipeline/archives  
```  
平台pvc会使用这些分布式存储目录下的subpath，所以如果你是rancher部署k8s集群，需要在kubelet容器中挂载主机的/data/k8s/目录到kubelet容器的/data/k8s/目录。
rancher修改kubelet容器挂载目录(选中集群-升级-编辑yaml)
```
    kubelet:
      extra_binds:
        - '/data/k8s:/data/k8s'
```


# 多集群

在每个集群完成平台部署。但仅保留其中一个web端。web端所在集群我们成为主集群，其他为远程集群。

1、远程集群卸载web端
```
# 删除web
kubectl delete -k cube/overlays
# 删除mysql和redis
kubectl delete -f redis/master.yaml
kubectl delete -f mysql/deploy.yaml
```
2、数据库全部连接到主集群的mysql

1）暴露主集群infra命名空间下mysql，可以外部ip的形式访问
2) 修改远程集群kubeflow命名空间，configmap:pipeline-install-config,修改ip端口账号密码。重启kubeflow命名空间ml-pipeline*的pod

3、添加配置文件

1、需要把在kubeconfig目录下面复制k8s集群的config文件，并规范命名，比如有个k8s集群，这里起名为dev1集群，那么将config文件粘贴到kubeconfig/dev1-kubeconfig
2、修改config.py配置文件：
```
# 所有训练集群的信息
CLUSTERS={
    # 和project expand里面的名称一致
    "dev1":{
        "NAME":"dev1",
        "KUBECONFIG":'/home/myapp/kubeconfig/dev1-kubeconfig',
        "K8S_DASHBOARD_CLUSTER":'/k8s/dashboard/cluster/',
        "KFP_HOST": 'http://ml-pipeline.kubeflow:8888',
        "PIPELINE_URL": '/pipeline/#/',
        # "JUPYTER_DOMAIN":"kubeflow.local.com",   # 如果没有域名就用*   有域名就配置成 HOST
        # "NNI_DOMAIN":'kubeflow.local.com'    # 如果没有域名就用*   有域名就配置成 HOST
    }
}
```
将config.py文件和kubeconfig文件更新上线就可以了。

这样cube就可以调度多个k8s集群了，但是还需要在项目中指定当前项目组下面的notebook/pipeline/service在哪个k8s集群调度。需要在项目组的扩展参数中添加

```
{
  "cluster": "dev1",
  "SERVICE_EXTERNAL_IP":"xx.xx.xx.xx"
}
```

# 多项目组

每个k8s集群的算力都可以划分为多个项目组。这些划分是通过机器label来实现的。

管理标注哪些机器属于哪些项目后，可通过项目组的expand字段控制项目组的调度机器
```
{
	"node_selector": "org=public"
}
```


# 多项目组算力均衡

多项目组之间的算力的均衡通过[schedules.py](https://github.com/tencentmusic/cube-studio/blob/master/myapp/tasks/schedules.py)中的adjust_node_resource任务实现。

基本原则是每5分钟，将可共享的机器(lable包含share=true)，从当前负载最小的项目组划分到负载最高的项目组，同时保证项目组的最小可用算力

